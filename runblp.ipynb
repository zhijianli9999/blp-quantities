{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, DataFramesMeta, LinearAlgebra, Distributions, Optim, Revise, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "string(@__DIR__) in LOAD_PATH || push!(LOAD_PATH, @__DIR__)\n",
    "using BLPmodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test imperfect overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×100 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I = 100;              # Number of consumers\n",
    "J = 3;                  # Number of firms\n",
    "K = 1;                  # Product characteristics\n",
    "nT = 10;                 # Number of markets\n",
    "# β = [1, -1];            # Preferences\n",
    "β = -1.;            # Preferences\n",
    "varζ = 3;               # Variance of the random taste\n",
    "rangeB = [100, 1000];       # consumers per market (e.g. census block)\n",
    "# varX = 2;               # Variance of X\n",
    "varξ = 1;               # Variance of xi\n",
    "ζ_ = rand(Normal(0,1), 1, 100); # Draw shocks (less)\n",
    "δ0 = zeros(1, size(ζ_, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>23 rows × 10 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>t</th><th>j</th><th>q</th><th>q0</th><th>agg_qj</th><th>agg_q0</th><th>B</th><th>agg_B</th><th>agg_s</th><th>agg_s0</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>1</td><td>140.308</td><td>181.797</td><td>1165.12</td><td>1489.55</td><td>616</td><td>4362</td><td>0.267106</td><td>0.341483</td></tr><tr><th>2</th><td>1</td><td>2</td><td>148.57</td><td>181.797</td><td>1423.78</td><td>1726.74</td><td>616</td><td>5124</td><td>0.277864</td><td>0.336991</td></tr><tr><th>3</th><td>1</td><td>3</td><td>145.326</td><td>181.797</td><td>2042.42</td><td>2488.69</td><td>616</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr><tr><th>4</th><td>2</td><td>1</td><td>196.523</td><td>245.564</td><td>1165.12</td><td>1489.55</td><td>626</td><td>4362</td><td>0.267106</td><td>0.341483</td></tr><tr><th>5</th><td>2</td><td>3</td><td>183.913</td><td>245.564</td><td>2042.42</td><td>2488.69</td><td>626</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr><tr><th>6</th><td>3</td><td>1</td><td>116.907</td><td>142.062</td><td>1165.12</td><td>1489.55</td><td>373</td><td>4362</td><td>0.267106</td><td>0.341483</td></tr><tr><th>7</th><td>3</td><td>3</td><td>114.031</td><td>142.062</td><td>2042.42</td><td>2488.69</td><td>373</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr><tr><th>8</th><td>4</td><td>2</td><td>234.4</td><td>261.794</td><td>1423.78</td><td>1726.74</td><td>731</td><td>5124</td><td>0.277864</td><td>0.336991</td></tr><tr><th>9</th><td>4</td><td>3</td><td>234.805</td><td>261.794</td><td>2042.42</td><td>2488.69</td><td>731</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr><tr><th>10</th><td>5</td><td>2</td><td>79.6421</td><td>93.6614</td><td>1423.78</td><td>1726.74</td><td>246</td><td>5124</td><td>0.277864</td><td>0.336991</td></tr><tr><th>11</th><td>5</td><td>3</td><td>72.6965</td><td>93.6614</td><td>2042.42</td><td>2488.69</td><td>246</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr><tr><th>12</th><td>6</td><td>2</td><td>246.257</td><td>274.455</td><td>1423.78</td><td>1726.74</td><td>789</td><td>5124</td><td>0.277864</td><td>0.336991</td></tr><tr><th>13</th><td>6</td><td>3</td><td>268.288</td><td>274.455</td><td>2042.42</td><td>2488.69</td><td>789</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr><tr><th>14</th><td>7</td><td>1</td><td>320.373</td><td>374.321</td><td>1165.12</td><td>1489.55</td><td>997</td><td>4362</td><td>0.267106</td><td>0.341483</td></tr><tr><th>15</th><td>7</td><td>3</td><td>302.306</td><td>374.321</td><td>2042.42</td><td>2488.69</td><td>997</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr><tr><th>16</th><td>8</td><td>1</td><td>180.987</td><td>239.652</td><td>1165.12</td><td>1489.55</td><td>785</td><td>4362</td><td>0.267106</td><td>0.341483</td></tr><tr><th>17</th><td>8</td><td>2</td><td>174.547</td><td>239.652</td><td>1423.78</td><td>1726.74</td><td>785</td><td>5124</td><td>0.277864</td><td>0.336991</td></tr><tr><th>18</th><td>8</td><td>3</td><td>189.814</td><td>239.652</td><td>2042.42</td><td>2488.69</td><td>785</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr><tr><th>19</th><td>9</td><td>2</td><td>333.132</td><td>369.228</td><td>1423.78</td><td>1726.74</td><td>992</td><td>5124</td><td>0.277864</td><td>0.336991</td></tr><tr><th>20</th><td>9</td><td>3</td><td>289.64</td><td>369.228</td><td>2042.42</td><td>2488.69</td><td>992</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr><tr><th>21</th><td>10</td><td>1</td><td>210.02</td><td>306.154</td><td>1165.12</td><td>1489.55</td><td>965</td><td>4362</td><td>0.267106</td><td>0.341483</td></tr><tr><th>22</th><td>10</td><td>2</td><td>207.228</td><td>306.154</td><td>1423.78</td><td>1726.74</td><td>965</td><td>5124</td><td>0.277864</td><td>0.336991</td></tr><tr><th>23</th><td>10</td><td>3</td><td>241.599</td><td>306.154</td><td>2042.42</td><td>2488.69</td><td>965</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& t & j & q & q0 & agg\\_qj & agg\\_q0 & B & agg\\_B & agg\\_s & agg\\_s0\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Float64 & Float64 & Float64 & Float64 & Int64 & Int64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 140.308 & 181.797 & 1165.12 & 1489.55 & 616 & 4362 & 0.267106 & 0.341483 \\\\\n",
       "\t2 & 1 & 2 & 148.57 & 181.797 & 1423.78 & 1726.74 & 616 & 5124 & 0.277864 & 0.336991 \\\\\n",
       "\t3 & 1 & 3 & 145.326 & 181.797 & 2042.42 & 2488.69 & 616 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\t4 & 2 & 1 & 196.523 & 245.564 & 1165.12 & 1489.55 & 626 & 4362 & 0.267106 & 0.341483 \\\\\n",
       "\t5 & 2 & 3 & 183.913 & 245.564 & 2042.42 & 2488.69 & 626 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\t6 & 3 & 1 & 116.907 & 142.062 & 1165.12 & 1489.55 & 373 & 4362 & 0.267106 & 0.341483 \\\\\n",
       "\t7 & 3 & 3 & 114.031 & 142.062 & 2042.42 & 2488.69 & 373 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\t8 & 4 & 2 & 234.4 & 261.794 & 1423.78 & 1726.74 & 731 & 5124 & 0.277864 & 0.336991 \\\\\n",
       "\t9 & 4 & 3 & 234.805 & 261.794 & 2042.42 & 2488.69 & 731 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\t10 & 5 & 2 & 79.6421 & 93.6614 & 1423.78 & 1726.74 & 246 & 5124 & 0.277864 & 0.336991 \\\\\n",
       "\t11 & 5 & 3 & 72.6965 & 93.6614 & 2042.42 & 2488.69 & 246 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\t12 & 6 & 2 & 246.257 & 274.455 & 1423.78 & 1726.74 & 789 & 5124 & 0.277864 & 0.336991 \\\\\n",
       "\t13 & 6 & 3 & 268.288 & 274.455 & 2042.42 & 2488.69 & 789 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\t14 & 7 & 1 & 320.373 & 374.321 & 1165.12 & 1489.55 & 997 & 4362 & 0.267106 & 0.341483 \\\\\n",
       "\t15 & 7 & 3 & 302.306 & 374.321 & 2042.42 & 2488.69 & 997 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\t16 & 8 & 1 & 180.987 & 239.652 & 1165.12 & 1489.55 & 785 & 4362 & 0.267106 & 0.341483 \\\\\n",
       "\t17 & 8 & 2 & 174.547 & 239.652 & 1423.78 & 1726.74 & 785 & 5124 & 0.277864 & 0.336991 \\\\\n",
       "\t18 & 8 & 3 & 189.814 & 239.652 & 2042.42 & 2488.69 & 785 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\t19 & 9 & 2 & 333.132 & 369.228 & 1423.78 & 1726.74 & 992 & 5124 & 0.277864 & 0.336991 \\\\\n",
       "\t20 & 9 & 3 & 289.64 & 369.228 & 2042.42 & 2488.69 & 992 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\t21 & 10 & 1 & 210.02 & 306.154 & 1165.12 & 1489.55 & 965 & 4362 & 0.267106 & 0.341483 \\\\\n",
       "\t22 & 10 & 2 & 207.228 & 306.154 & 1423.78 & 1726.74 & 965 & 5124 & 0.277864 & 0.336991 \\\\\n",
       "\t23 & 10 & 3 & 241.599 & 306.154 & 2042.42 & 2488.69 & 965 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m23×10 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m t     \u001b[0m\u001b[1m j     \u001b[0m\u001b[1m q        \u001b[0m\u001b[1m q0       \u001b[0m\u001b[1m agg_qj  \u001b[0m\u001b[1m agg_q0  \u001b[0m\u001b[1m B     \u001b[0m\u001b[1m agg_B \u001b[0m\u001b[1m agg_s\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     1      1  140.308   181.797   1165.12  1489.55    616   4362  0.267 ⋯\n",
       "   2 │     1      2  148.57    181.797   1423.78  1726.74    616   5124  0.277\n",
       "   3 │     1      3  145.326   181.797   2042.42  2488.69    616   7120  0.286\n",
       "   4 │     2      1  196.523   245.564   1165.12  1489.55    626   4362  0.267\n",
       "   5 │     2      3  183.913   245.564   2042.42  2488.69    626   7120  0.286 ⋯\n",
       "   6 │     3      1  116.907   142.062   1165.12  1489.55    373   4362  0.267\n",
       "   7 │     3      3  114.031   142.062   2042.42  2488.69    373   7120  0.286\n",
       "   8 │     4      2  234.4     261.794   1423.78  1726.74    731   5124  0.277\n",
       "  ⋮  │   ⋮      ⋮       ⋮         ⋮         ⋮        ⋮       ⋮      ⋮       ⋮  ⋱\n",
       "  17 │     8      2  174.547   239.652   1423.78  1726.74    785   5124  0.277 ⋯\n",
       "  18 │     8      3  189.814   239.652   2042.42  2488.69    785   7120  0.286\n",
       "  19 │     9      2  333.132   369.228   1423.78  1726.74    992   5124  0.277\n",
       "  20 │     9      3  289.64    369.228   2042.42  2488.69    992   7120  0.286\n",
       "  21 │    10      1  210.02    306.154   1165.12  1489.55    965   4362  0.267 ⋯\n",
       "  22 │    10      2  207.228   306.154   1423.78  1726.74    965   5124  0.277\n",
       "  23 │    10      3  241.599   306.154   2042.42  2488.69    965   7120  0.286\n",
       "\u001b[36m                                                    2 columns and 8 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_thresh = 0.5\n",
    "df = BLPmodule.build_dist_data(J, β, nT, rangeB, varζ, varξ, dist_thresh)\n",
    "df[:, Cols(\"t\", \"j\", r\"q\", r\"B\", r\"agg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 7 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>j</th><th>dist</th><th>agg_qj</th><th>agg_q0</th><th>agg_B</th><th>agg_s</th><th>agg_s0</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>0.295122</td><td>1165.12</td><td>1489.55</td><td>4362</td><td>0.267106</td><td>0.341483</td></tr><tr><th>2</th><td>2</td><td>0.481277</td><td>1423.78</td><td>1726.74</td><td>5124</td><td>0.277864</td><td>0.336991</td></tr><tr><th>3</th><td>3</td><td>0.205558</td><td>2042.42</td><td>2488.69</td><td>7120</td><td>0.286857</td><td>0.349535</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& j & dist & agg\\_qj & agg\\_q0 & agg\\_B & agg\\_s & agg\\_s0\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64 & Float64 & Int64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 0.295122 & 1165.12 & 1489.55 & 4362 & 0.267106 & 0.341483 \\\\\n",
       "\t2 & 2 & 0.481277 & 1423.78 & 1726.74 & 5124 & 0.277864 & 0.336991 \\\\\n",
       "\t3 & 3 & 0.205558 & 2042.42 & 2488.69 & 7120 & 0.286857 & 0.349535 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m j     \u001b[0m\u001b[1m dist     \u001b[0m\u001b[1m agg_qj  \u001b[0m\u001b[1m agg_q0  \u001b[0m\u001b[1m agg_B \u001b[0m\u001b[1m agg_s    \u001b[0m\u001b[1m agg_s0   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────────────────\n",
       "   1 │     1  0.295122  1165.12  1489.55   4362  0.267106  0.341483\n",
       "   2 │     2  0.481277  1423.78  1726.74   5124  0.277864  0.336991\n",
       "   3 │     3  0.205558  2042.42  2488.69   7120  0.286857  0.349535"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_j = df[Not(findall(nonunique(df[!,[:j]]))), Cols(\"j\", \"dist\", r\"agg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations:2\n",
      "deltas:[7.0605773124387206, 7.261067358009756, 7.621890274362473]\n"
     ]
    }
   ],
   "source": [
    "using BLPmodule\n",
    "deltas = BLPmodule.loop(df_j.agg_qj);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1165.117608537323, 1423.7754045515073, 2042.4192158784454]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 1165.1176085373243\n",
       " 1423.7754045515067\n",
       " 2042.419215878445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(BLPmodule.simple_shares(deltas))\n",
    "df_j.agg_qj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations:2\n",
      "deltas:[-1.3201086343228527, -1.2806233050068698, -1.248772730043549]\n"
     ]
    }
   ],
   "source": [
    "using BLPmodule\n",
    "deltas = BLPmodule.loop(df_j.agg_s);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2671062834794416, 0.2778640524105203, 0.2868566314436018]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 0.2671062834794416\n",
       " 0.2778640524105204\n",
       " 0.2868566314436018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(BLPmodule.simple_shares(deltas))\n",
    "df_j.agg_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff below are wrong (working with the original functions, trying to work with shares). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_x = repeat([0.], J);\n",
    "aux_t = repeat([1], J);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final counter: 10001\n",
      "deltas:[8.075277635145266, 8.114762964461251, 8.146613539424571]\n",
      "computed shares:       [0.32107590933717406, 0.3340073177525479, 0.34481687435571723]\n",
      "true aggregate shares: [0.2671062834794416, 0.2778640524105204, 0.2868566314436018]\n"
     ]
    }
   ],
   "source": [
    "using BLPmodule\n",
    "deltas = BLPmodule.compute_delta(df_j.agg_s, df_j.agg_s0, aux_x , ζ_, aux_t);\n",
    "shares = BLPmodule.implied_shares(aux_x, ζ_, deltas, δ0)\n",
    "println(\"computed shares:       \", shares)\n",
    "println(\"true aggregate shares: \", df_j.agg_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final counter: 10001\n",
      "deltas:[7.831237224455996, 8.031727270027027, 8.392550186379749]\n",
      "computed shares:       [0.25154883915743215, 0.3073930456560951, 0.44095821663191237]\n",
      "true aggregate shares: [0.2671062834794416, 0.2778640524105204, 0.2868566314436018]\n"
     ]
    }
   ],
   "source": [
    "# using quantities\n",
    "using BLPmodule\n",
    "deltas = BLPmodule.compute_delta(df_j.agg_qj, df_j.agg_q0, aux_x, ζ_, aux_t);\n",
    "shares = BLPmodule.implied_shares(aux_x, ζ_, deltas, δ0)\n",
    "println(\"computed shares:       \", shares)\n",
    "println(\"true aggregate shares: \", df_j.agg_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# δ0 = zeros(1, size(ζ_, 2))\n",
    "# for t in unique(T)\n",
    "#     tind = df.t.==t\n",
    "#     shares = BLPmodule.implied_shares(X_[tind,:], ζ_, deltas1, δ0)\n",
    "#     println(\"computed shares: \", shares)\n",
    "# end\n",
    "# println(agg_shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using BLPmodule\n",
    "# Minimize GMM objective function\n",
    "# varζ_ = optimize(x -> BLPmodule.GMM(q_j_, q0_, X_, Z_, ζ_, T, IV_, x[1])[1], [3.0], LBFGS()).minimizer[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# β_blp = BLPmodule.GMM(q_j_, q0_, X_, Z_, ζ_, T, IV_, varζ_)[2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Estimated BLP coefficients: $β_blp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute logit estimate\n",
    "# y = log.(df.s) - log.(df.s0)\n",
    "# β_logit = inv(IV_' * X_) * (IV_' * y)\n",
    "# print(\"Estimated logit coefficients: $β_logit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
